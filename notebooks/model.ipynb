{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:44.873357Z",
     "iopub.status.busy": "2023-10-30T15:45:44.873056Z",
     "iopub.status.idle": "2023-10-30T15:45:50.512221Z",
     "shell.execute_reply": "2023-10-30T15:45:50.511415Z",
     "shell.execute_reply.started": "2023-10-30T15:45:44.873330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.514346Z",
     "iopub.status.busy": "2023-10-30T15:45:50.513886Z",
     "iopub.status.idle": "2023-10-30T15:45:50.522654Z",
     "shell.execute_reply": "2023-10-30T15:45:50.521758Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.514319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MANUAL_SEED = 42\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.524040Z",
     "iopub.status.busy": "2023-10-30T15:45:50.523804Z",
     "iopub.status.idle": "2023-10-30T15:45:50.639351Z",
     "shell.execute_reply": "2023-10-30T15:45:50.638450Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.524019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df)=2829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Animation</th>\n",
       "      <th>genre_Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_1672</th>\n",
       "      <th>rating_1673</th>\n",
       "      <th>rating_1674</th>\n",
       "      <th>rating_1675</th>\n",
       "      <th>rating_1676</th>\n",
       "      <th>rating_1677</th>\n",
       "      <th>rating_1678</th>\n",
       "      <th>rating_1679</th>\n",
       "      <th>rating_1680</th>\n",
       "      <th>rating_1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.569647</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.07155</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.569647</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.07155</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.569647</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.07155</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.593130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.593130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5070 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   age  gender  occupation  zip_code  genre_unknown  genre_Action  \\\n",
       "0      1.0  0.24     1.0    0.904762  0.569647       0.001704      0.127768   \n",
       "1      1.0  0.24     1.0    0.904762  0.569647       0.001704      0.127768   \n",
       "2      1.0  0.24     1.0    0.904762  0.569647       0.001704      0.127768   \n",
       "3      2.0  0.53     0.0    0.619048  0.593130       0.000000      0.081301   \n",
       "4      2.0  0.53     0.0    0.619048  0.593130       0.000000      0.081301   \n",
       "\n",
       "   genre_Adventure  genre_Animation  genre_Children's  ...  rating_1672  \\\n",
       "0          0.07155         0.020443          0.042589  ...          0.0   \n",
       "1          0.07155         0.020443          0.042589  ...          0.0   \n",
       "2          0.07155         0.020443          0.042589  ...          0.0   \n",
       "3          0.02439         0.008130          0.032520  ...          0.0   \n",
       "4          0.02439         0.008130          0.032520  ...          0.0   \n",
       "\n",
       "   rating_1673  rating_1674  rating_1675  rating_1676  rating_1677  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   rating_1678  rating_1679  rating_1680  rating_1681  \n",
       "0          0.0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 5070 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/users_with_masks.csv\", sep=\"\\t\")\n",
    "print(f\"{len(df)=}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MOVIES = 1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:04.094446Z",
     "iopub.status.busy": "2023-10-30T15:46:04.093174Z",
     "iopub.status.idle": "2023-10-30T15:46:04.105119Z",
     "shell.execute_reply": "2023-10-30T15:46:04.104195Z",
     "shell.execute_reply.started": "2023-10-30T15:46:04.094407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RecommendationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.inputs = self.df.iloc[:, : 24 + NUM_MOVIES].to_numpy()\n",
    "        self.masks = self.df.iloc[:, 24 + NUM_MOVIES : 24 + NUM_MOVIES * 2].to_numpy()\n",
    "        self.targets = self.df.iloc[\n",
    "            :, 24 + NUM_MOVIES * 2 : 24 + NUM_MOVIES * 3\n",
    "        ].to_numpy()\n",
    "\n",
    "    def _mask(self, value: np.ndarray, mask: np.ndarray) -> np.ndarray:\n",
    "        return value[mask.nonzero()]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[np.ndarray, int, np.ndarray]:\n",
    "        mask = self.masks[idx]\n",
    "        input_data = self.inputs[idx]\n",
    "        masked_target = self.targets[idx][mask.nonzero()]\n",
    "        return input_data, len(mask.nonzero()[0]), masked_target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:04.106997Z",
     "iopub.status.busy": "2023-10-30T15:46:04.106618Z",
     "iopub.status.idle": "2023-10-30T15:46:07.777044Z",
     "shell.execute_reply": "2023-10-30T15:46:07.775971Z",
     "shell.execute_reply.started": "2023-10-30T15:46:04.106969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = RecommendationDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.781101Z",
     "iopub.status.busy": "2023-10-30T15:46:07.780816Z",
     "iopub.status.idle": "2023-10-30T15:46:07.811091Z",
     "shell.execute_reply": "2023-10-30T15:46:07.810236Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.781077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset)=2547\n",
      "len(val_dataset)=282\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    ")\n",
    "print(f\"{len(train_dataset)=}\")\n",
    "print(f\"{len(val_dataset)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.812402Z",
     "iopub.status.busy": "2023-10-30T15:46:07.812119Z",
     "iopub.status.idle": "2023-10-30T15:46:07.816776Z",
     "shell.execute_reply": "2023-10-30T15:46:07.815820Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.812377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.820703Z",
     "iopub.status.busy": "2023-10-30T15:46:07.820331Z",
     "iopub.status.idle": "2023-10-30T15:46:07.830576Z",
     "shell.execute_reply": "2023-10-30T15:46:07.829731Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.820679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.831643Z",
     "iopub.status.busy": "2023-10-30T15:46:07.831399Z",
     "iopub.status.idle": "2023-10-30T15:46:07.842123Z",
     "shell.execute_reply": "2023-10-30T15:46:07.841338Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.831622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch: list) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_data_batch, mask_length_batch, masked_target_batch = [], [], []\n",
    "    for input_data, mask_length, masked_target in batch:\n",
    "        input_data_batch.append(torch.Tensor(input_data))\n",
    "        mask_length_batch.append(mask_length)\n",
    "        masked_target_batch.append(torch.Tensor(masked_target))\n",
    "\n",
    "    # return pad_sequence(input_data_batch).long(), torch.Tensor(mask_length_batch), pad_sequence(masked_target_batch).long()\n",
    "    return (\n",
    "        torch.swapaxes(pad_sequence(input_data_batch), 0, 1),\n",
    "        torch.Tensor(mask_length_batch),\n",
    "        torch.swapaxes(pad_sequence(masked_target_batch), 0, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.844380Z",
     "iopub.status.busy": "2023-10-30T15:46:07.843256Z",
     "iopub.status.idle": "2023-10-30T15:46:07.919445Z",
     "shell.execute_reply": "2023-10-30T15:46:07.918458Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.844355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1706])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 154])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    inp, mask_size, out = batch\n",
    "    print(inp.shape)\n",
    "    print(mask_size.shape)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.921039Z",
     "iopub.status.busy": "2023-10-30T15:46:07.920762Z",
     "iopub.status.idle": "2023-10-30T15:46:07.948728Z",
     "shell.execute_reply": "2023-10-30T15:46:07.947826Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.921015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.4200e+02, 3.3000e-01, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.8800e+02, 3.4000e-01, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.4600e+02, 4.5000e-01, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [7.2900e+02, 1.9000e-01, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [4.8300e+02, 2.9000e-01, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [4.6000e+01, 2.7000e-01, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([  8.,  30.,  10.,   8.,  56.,   8.,  14., 150.,   8.,  22., 142.,  78.,\n",
       "          20.,  14.,  42.,  18.,   8.,  88., 132.,  20.,  28.,   8.,  16., 146.,\n",
       "          18.,  38.,   8., 108.,  20.,   8.,  22.,  10.]),\n",
       " tensor([[0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.8000, 0.0000, 0.4000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8000, 0.6000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.4000, 0.6000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.8000, 0.4000, 0.4000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.6000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = train_dataloader._get_iterator()\n",
    "\n",
    "it._next_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 24 + NUM_MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.950125Z",
     "iopub.status.busy": "2023-10-30T15:46:07.949851Z",
     "iopub.status.idle": "2023-10-30T15:46:07.967626Z",
     "shell.execute_reply": "2023-10-30T15:46:07.966641Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.950101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RecSys(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim1: int = 1024,\n",
    "        hidden_dim2: int = 1024,\n",
    "    ):\n",
    "        super(RecSys, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_SIZE, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, NUM_MOVIES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.sigmoid(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:13.722557Z",
     "iopub.status.busy": "2023-10-30T15:46:13.722268Z",
     "iopub.status.idle": "2023-10-30T15:46:14.170700Z",
     "shell.execute_reply": "2023-10-30T15:46:14.169643Z",
     "shell.execute_reply.started": "2023-10-30T15:46:13.722526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "model = RecSys()\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.172208Z",
     "iopub.status.busy": "2023-10-30T15:46:14.171914Z",
     "iopub.status.idle": "2023-10-30T15:46:14.185601Z",
     "shell.execute_reply": "2023-10-30T15:46:14.184636Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.172183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    for batch in loop:\n",
    "        input_data, mask_sizes, masked_target = batch\n",
    "        input_data, masked_target = input_data.to(DEVICE), masked_target.to(DEVICE)\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        model_out = model(input_data)\n",
    "        outputs = model_out[:, : masked_target.shape[1]]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(outputs.reshape(-1), masked_target.reshape(-1))\n",
    "        # loss = loss_fn(outputs, masked_target)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        total += masked_target.shape[1]\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / total})\n",
    "\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for batch in loop:\n",
    "            input_data, mask_sizes, masked_target = batch\n",
    "            input_data, masked_target = input_data.to(DEVICE), masked_target.to(DEVICE)\n",
    "\n",
    "            model_out = model(input_data)\n",
    "            outputs = model_out[:, : masked_target.shape[1]]\n",
    "\n",
    "            loss = loss_fn(outputs.reshape(-1), masked_target.reshape(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            total += masked_target.shape[1]\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.357029Z",
     "iopub.status.busy": "2023-10-30T15:46:14.356687Z",
     "iopub.status.idle": "2023-10-30T16:00:30.509074Z",
     "shell.execute_reply": "2023-10-30T16:00:30.508269Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.356996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: train: 100%|██████████| 80/80 [00:01<00:00, 44.94it/s, loss=3.31]\n",
      "Epoch 1: val: 100%|██████████| 9/9 [00:00<00:00, 123.28it/s, loss=1.89]\n",
      "Epoch 2: train: 100%|██████████| 80/80 [00:01<00:00, 62.31it/s, loss=1.67]\n",
      "Epoch 2: val: 100%|██████████| 9/9 [00:00<00:00, 94.74it/s, loss=1.6]\n",
      "Epoch 3: train: 100%|██████████| 80/80 [00:01<00:00, 61.78it/s, loss=1.52]\n",
      "Epoch 3: val: 100%|██████████| 9/9 [00:00<00:00, 107.15it/s, loss=1.47]\n",
      "Epoch 4: train: 100%|██████████| 80/80 [00:01<00:00, 64.67it/s, loss=1.44]\n",
      "Epoch 4: val: 100%|██████████| 9/9 [00:00<00:00, 116.89it/s, loss=1.34]\n",
      "Epoch 5: train: 100%|██████████| 80/80 [00:01<00:00, 66.39it/s, loss=1.37]\n",
      "Epoch 5: val: 100%|██████████| 9/9 [00:00<00:00, 118.42it/s, loss=1.27]\n",
      "Epoch 6: train: 100%|██████████| 80/80 [00:01<00:00, 63.54it/s, loss=1.29]\n",
      "Epoch 6: val: 100%|██████████| 9/9 [00:00<00:00, 118.44it/s, loss=1.23]\n",
      "Epoch 7: train: 100%|██████████| 80/80 [00:01<00:00, 59.08it/s, loss=1.24]\n",
      "Epoch 7: val: 100%|██████████| 9/9 [00:00<00:00, 120.00it/s, loss=1.13]\n",
      "Epoch 8: train: 100%|██████████| 80/80 [00:01<00:00, 59.97it/s, loss=1.17]\n",
      "Epoch 8: val: 100%|██████████| 9/9 [00:00<00:00, 107.15it/s, loss=1.14]\n",
      "Epoch 9: train: 100%|██████████| 80/80 [00:01<00:00, 64.99it/s, loss=1.15]\n",
      "Epoch 9: val: 100%|██████████| 9/9 [00:00<00:00, 103.45it/s, loss=1.12]\n",
      "Epoch 10: train: 100%|██████████| 80/80 [00:01<00:00, 58.27it/s, loss=1.13]\n",
      "Epoch 10: val: 100%|██████████| 9/9 [00:00<00:00, 112.50it/s, loss=1.06]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "best_loss = 1e10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    val_loss = val_one_epoch(model, val_dataloader, loss_fn, epoch)\n",
    "    if val_loss <= best_loss:\n",
    "        val_loss = best_loss\n",
    "        torch.save(model, \"../models/solution_model\")\n",
    "\n",
    "\n",
    "best = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Inno\\PMLDL\\Assignments\\movie-recommender-system\\notebooks\\model.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/model.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.510782Z",
     "iopub.status.busy": "2023-10-30T16:00:30.510404Z",
     "iopub.status.idle": "2023-10-30T16:00:30.592431Z",
     "shell.execute_reply": "2023-10-30T16:00:30.591458Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.510749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetoxTransformer(\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (input_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(14747, 320)\n",
       "  )\n",
       "  (output_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(14747, 320)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=320, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=320, bias=True)\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=320, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=320, bias=True)\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=320, out_features=14747, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../models/solution_model\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.594167Z",
     "iopub.status.busy": "2023-10-30T16:00:30.593792Z",
     "iopub.status.idle": "2023-10-30T16:00:30.601298Z",
     "shell.execute_reply": "2023-10-30T16:00:30.600267Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.594133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "TOKENIZER = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "BOS_IDX, EOS_IDX, PAD_IDX = vocab([\"<bos>\", \"<eos>\", \"<pad>\"])\n",
    "\n",
    "\n",
    "def preprocess_text(text: str, vocab=vocab) -> torch.Tensor:\n",
    "    return torch.tensor([BOS_IDX] + vocab(TOKENIZER(text.lower())) + [EOS_IDX])\n",
    "\n",
    "\n",
    "def decode_tokens(tokens: torch.Tensor, vocab=vocab) -> str:\n",
    "    text = (\n",
    "        \" \".join(vocab.lookup_tokens(list(tokens.cpu().numpy())))\n",
    "        .replace(\"<bos>\", \"\")\n",
    "        .replace(\"<eos>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    return re.sub(\" +\", \" \", re.sub(r'\\s([?.!\"](?:\\s|$))', r\"\\1\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.602855Z",
     "iopub.status.busy": "2023-10-30T16:00:30.602541Z",
     "iopub.status.idle": "2023-10-30T16:00:30.614496Z",
     "shell.execute_reply": "2023-10-30T16:00:30.613626Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.602830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def greedy_decode(\n",
    "    model: torch.nn.Module,\n",
    "    src: torch.Tensor,\n",
    "    src_mask: torch.Tensor,\n",
    "    max_size: int,\n",
    "    start_symbol: int,\n",
    ") -> torch.Tensor:\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    answer = torch.ones(1, 1).fill_(start_symbol).long().to(DEVICE)\n",
    "    for _ in range(max_size - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "\n",
    "        trg_mask = (generate_square_subsequent_mask(answer.size(0)).bool()).to(DEVICE)\n",
    "        outputs = model.decode(answer, memory, trg_mask)\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "\n",
    "        probabilities = model.generator(outputs[:, -1])\n",
    "        _, next_word = torch.max(probabilities, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        answer = torch.cat(\n",
    "            [answer, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return answer\n",
    "\n",
    "\n",
    "def detoxify(model: torch.nn.Module, src_sentence: str) -> str:\n",
    "    src = preprocess_text(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    output_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_size=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    return decode_tokens(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.615983Z",
     "iopub.status.busy": "2023-10-30T16:00:30.615665Z",
     "iopub.status.idle": "2023-10-30T16:01:13.178242Z",
     "shell.execute_reply": "2023-10-30T16:01:13.177355Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.615944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:42<00:00, 11.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model_answers = []\n",
    "for i, r in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    model_answers.append(detoxify(model, r[\"toxic\"][:MAX_SIZE]))\n",
    "\n",
    "\n",
    "test_df[\"generated\"] = model_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:01:13.180102Z",
     "iopub.status.busy": "2023-10-30T16:01:13.179690Z",
     "iopub.status.idle": "2023-10-30T16:01:13.192022Z",
     "shell.execute_reply": "2023-10-30T16:01:13.190951Z",
     "shell.execute_reply.started": "2023-10-30T16:01:13.180054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's feeding time at the fucking zoo!</td>\n",
       "      <td>it's time to eat at the zoo!</td>\n",
       "      <td>it 's about it and the floor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone here bet on the hero and lost their a...</td>\n",
       "      <td>they all took a hero and lost everything.</td>\n",
       "      <td>everyone 's here on your hero and all those th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then I got to come home to Melvin and his bull...</td>\n",
       "      <td>then I'm going home and Melvin's there.</td>\n",
       "      <td>then i have to come home and left his voice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara here was hoping to pick your brains.</td>\n",
       "      <td>Sara was hoping you could handle her.</td>\n",
       "      <td>there was here i was hoping i 'd pick you your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, that's stupid. If anyone wants to tell me ...</td>\n",
       "      <td>if anyone wants to tell me what's going on, I'...</td>\n",
       "      <td>if anyone wants me to tell me what 's going on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               toxic  \\\n",
       "0              It's feeding time at the fucking zoo!   \n",
       "1  Everyone here bet on the hero and lost their a...   \n",
       "2  Then I got to come home to Melvin and his bull...   \n",
       "3          Sara here was hoping to pick your brains.   \n",
       "4  Oh, that's stupid. If anyone wants to tell me ...   \n",
       "\n",
       "                                            nontoxic  \\\n",
       "0                       it's time to eat at the zoo!   \n",
       "1          they all took a hero and lost everything.   \n",
       "2            then I'm going home and Melvin's there.   \n",
       "3              Sara was hoping you could handle her.   \n",
       "4  if anyone wants to tell me what's going on, I'...   \n",
       "\n",
       "                                           generated  \n",
       "0                      it 's about it and the floor.  \n",
       "1  everyone 's here on your hero and all those th...  \n",
       "2       then i have to come home and left his voice.  \n",
       "3  there was here i was hoping i 'd pick you your...  \n",
       "4  if anyone wants me to tell me what 's going on...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:01:13.193675Z",
     "iopub.status.busy": "2023-10-30T16:01:13.193349Z",
     "iopub.status.idle": "2023-10-30T16:01:13.211273Z",
     "shell.execute_reply": "2023-10-30T16:01:13.210526Z",
     "shell.execute_reply.started": "2023-10-30T16:01:13.193649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../data/generated/custom_transformer.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
