{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating loss 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:44.873357Z",
     "iopub.status.busy": "2023-10-30T15:45:44.873056Z",
     "iopub.status.idle": "2023-10-30T15:45:50.512221Z",
     "shell.execute_reply": "2023-10-30T15:45:50.511415Z",
     "shell.execute_reply.started": "2023-10-30T15:45:44.873330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.514346Z",
     "iopub.status.busy": "2023-10-30T15:45:50.513886Z",
     "iopub.status.idle": "2023-10-30T15:45:50.522654Z",
     "shell.execute_reply": "2023-10-30T15:45:50.521758Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.514319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MANUAL_SEED = 42\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.524040Z",
     "iopub.status.busy": "2023-10-30T15:45:50.523804Z",
     "iopub.status.idle": "2023-10-30T15:45:50.639351Z",
     "shell.execute_reply": "2023-10-30T15:45:50.638450Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.524019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[5.0, 3.0, 4.0, 3.0, 3.0, 5.0, 4.0, 1.0, 5.0, ...</td>\n",
       "      <td>[5.0, 3.0, 4.0, 3.0, 3.0, 5.0, 4.0, 1.0, 5.0, ...</td>\n",
       "      <td>[0.0019047619047619048, 0.1219047619047619, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.08333333333333333, 0.02777777777777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.10810810810810811, 0.03603603603603603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.14814814814814814, 0.07407407407407407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0028735632183908046, 0.14942528735632185, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   age  gender  occupation  \\\n",
       "0      0  0.24     1.0        19.0   \n",
       "1      1  0.53     0.0        13.0   \n",
       "2      2  0.23     1.0        20.0   \n",
       "3      3  0.24     1.0        19.0   \n",
       "4      4  0.33     0.0        13.0   \n",
       "\n",
       "                                               input  \\\n",
       "0  [5.0, 3.0, 4.0, 3.0, 3.0, 5.0, 4.0, 1.0, 5.0, ...   \n",
       "1  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              output  \\\n",
       "0  [5.0, 3.0, 4.0, 3.0, 3.0, 5.0, 4.0, 1.0, 5.0, ...   \n",
       "1  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [0.0019047619047619048, 0.1219047619047619, 0....  \n",
       "1  [0.0, 0.08333333333333333, 0.02777777777777777...  \n",
       "2  [0.0, 0.10810810810810811, 0.03603603603603603...  \n",
       "3  [0.0, 0.14814814814814814, 0.07407407407407407...  \n",
       "4  [0.0028735632183908046, 0.14942528735632185, 0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(\".\", \"../data/raw/user_masks/\")\n",
    "loaded_dfs = [\n",
    "    pd.read_csv(os.path.join(path, file_name)) for file_name in os.listdir(path)\n",
    "]\n",
    "df = pd.concat(loaded_dfs).drop(columns=[\"user_id\"]).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(literal_eval(df[\"genres\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_df)=22915\n",
      "len(val_df)=2546\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "train_df = df.sample(frac=TRAIN_RATIO, random_state=MANUAL_SEED)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_df.drop(columns=[\"index\"], inplace=True)\n",
    "val_df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "print(f\"{len(train_df)=}\")\n",
    "print(f\"{len(val_df)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MOVIES = 1682\n",
    "USER_FEATURES = 3 + 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:04.094446Z",
     "iopub.status.busy": "2023-10-30T15:46:04.093174Z",
     "iopub.status.idle": "2023-10-30T15:46:04.105119Z",
     "shell.execute_reply": "2023-10-30T15:46:04.104195Z",
     "shell.execute_reply.started": "2023-10-30T15:46:04.094407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RecommendationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        features = []\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            features.append(row[:3].tolist() + literal_eval(row[\"genres\"]))\n",
    "            inputs.append(literal_eval(row[\"input\"]))\n",
    "            targets.append(literal_eval(row[\"output\"]))\n",
    "\n",
    "        self.features = np.array(features)\n",
    "        self.inputs = np.array(inputs) / 5\n",
    "        self.targets = np.array(targets) / 5\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        input_ratings = self.inputs[idx]\n",
    "        # print(input_ratings)\n",
    "        input_data = np.concatenate([self.features[idx], input_ratings])\n",
    "        mask = input_ratings == 0\n",
    "        return input_data, mask, self.targets[idx]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.781101Z",
     "iopub.status.busy": "2023-10-30T15:46:07.780816Z",
     "iopub.status.idle": "2023-10-30T15:46:07.811091Z",
     "shell.execute_reply": "2023-10-30T15:46:07.810236Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.781077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/22915 [00:00<05:38, 67.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22915/22915 [03:22<00:00, 113.11it/s]\n",
      "100%|██████████| 2546/2546 [00:17<00:00, 144.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset)=22915\n",
      "len(val_dataset)=2546\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = (\n",
    "    # RecommendationDataset(train_df.iloc[:100, :]),\n",
    "    # RecommendationDataset(val_df.iloc[:100, :]),\n",
    "    RecommendationDataset(train_df),\n",
    "    RecommendationDataset(val_df),\n",
    ")\n",
    "print(f\"{len(train_dataset)=}\")\n",
    "print(f\"{len(val_dataset)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.812402Z",
     "iopub.status.busy": "2023-10-30T15:46:07.812119Z",
     "iopub.status.idle": "2023-10-30T15:46:07.816776Z",
     "shell.execute_reply": "2023-10-30T15:46:07.815820Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.812377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.831643Z",
     "iopub.status.busy": "2023-10-30T15:46:07.831399Z",
     "iopub.status.idle": "2023-10-30T15:46:07.842123Z",
     "shell.execute_reply": "2023-10-30T15:46:07.841338Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.831622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch: list) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_data_batch, mask_batch, target_batch = [], [], []\n",
    "    for input_data, mask, target in batch:\n",
    "        input_data_batch.append(input_data)\n",
    "        mask_batch.append(mask)\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return (\n",
    "        torch.Tensor(input_data_batch),\n",
    "        torch.Tensor(mask_batch).bool(),\n",
    "        torch.Tensor(target_batch),\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.844380Z",
     "iopub.status.busy": "2023-10-30T15:46:07.843256Z",
     "iopub.status.idle": "2023-10-30T15:46:07.919445Z",
     "shell.execute_reply": "2023-10-30T15:46:07.918458Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.844355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1704])\n",
      "torch.Size([32, 1682])\n",
      "torch.Size([32, 1682])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    inp, mask, out = batch\n",
    "    print(inp.shape)\n",
    "    print(mask.shape)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.921039Z",
     "iopub.status.busy": "2023-10-30T15:46:07.920762Z",
     "iopub.status.idle": "2023-10-30T15:46:07.948728Z",
     "shell.execute_reply": "2023-10-30T15:46:07.947826Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.921015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1700,  1.0000, 18.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1900,  0.0000, 18.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4200,  1.0000, 14.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.2300,  1.0000, 13.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2700,  0.0000, 18.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2500,  1.0000, 14.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
       "         [False,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True, False,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]]),\n",
       " tensor([[0.6000, 0.6000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.8000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.6000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.8000, 0.0000, 0.6000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = train_dataloader._get_iterator()\n",
    "\n",
    "it._next_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = USER_FEATURES + NUM_MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.950125Z",
     "iopub.status.busy": "2023-10-30T15:46:07.949851Z",
     "iopub.status.idle": "2023-10-30T15:46:07.967626Z",
     "shell.execute_reply": "2023-10-30T15:46:07.966641Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.950101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RecSys(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim1: int = 1024,\n",
    "        hidden_dim2: int = 1024,\n",
    "        hidden_dim3: int = 1024,\n",
    "    ):\n",
    "        super(RecSys, self).__init__()\n",
    "        self.d1 = nn.Dropout(0.1)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(INPUT_SIZE, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, NUM_MOVIES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.d2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.sigmoid(self.fc4(x))\n",
    "        # return F.relu(self.fc4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:13.722557Z",
     "iopub.status.busy": "2023-10-30T15:46:13.722268Z",
     "iopub.status.idle": "2023-10-30T15:46:14.170700Z",
     "shell.execute_reply": "2023-10-30T15:46:14.169643Z",
     "shell.execute_reply.started": "2023-10-30T15:46:13.722526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "model = RecSys()\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.172208Z",
     "iopub.status.busy": "2023-10-30T15:46:14.171914Z",
     "iopub.status.idle": "2023-10-30T15:46:14.185601Z",
     "shell.execute_reply": "2023-10-30T15:46:14.184636Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.172183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    for batch in loop:\n",
    "        input_data, mask, target = batch\n",
    "        input_data, target, mask = (\n",
    "            input_data.to(DEVICE),\n",
    "            target.to(DEVICE),\n",
    "            mask.to(DEVICE),\n",
    "        )\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(input_data)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # loss = loss_fn(\n",
    "        #     torch.masked_select(outputs, mask), torch.masked_select(target, mask)\n",
    "        # )\n",
    "        # loss = loss_fn(outputs, target)\n",
    "        loss = loss_fn(outputs, (target > 0).float())\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        total += target.shape[1]\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / total})\n",
    "\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for batch in loop:\n",
    "            input_data, mask, target = batch\n",
    "            input_data, target, mask = (\n",
    "                input_data.to(DEVICE),\n",
    "                target.to(DEVICE),\n",
    "                mask.to(DEVICE),\n",
    "            )\n",
    "\n",
    "            outputs = model(input_data)\n",
    "\n",
    "            # loss = loss_fn(\n",
    "            #     torch.masked_select(outputs, mask), torch.masked_select(target, mask)\n",
    "            # )\n",
    "            # loss = loss_fn(outputs, target)\n",
    "\n",
    "            loss = loss_fn(outputs, (target > 0).float())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            total += target.shape[1]\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.357029Z",
     "iopub.status.busy": "2023-10-30T15:46:14.356687Z",
     "iopub.status.idle": "2023-10-30T16:00:30.509074Z",
     "shell.execute_reply": "2023-10-30T16:00:30.508269Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.356996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: train: 100%|██████████| 717/717 [00:34<00:00, 21.01it/s, loss=8.2e-5]  \n",
      "Epoch 1: val: 100%|██████████| 80/80 [00:03<00:00, 25.33it/s, loss=6.34e-5]\n",
      "Epoch 2: train: 100%|██████████| 717/717 [00:36<00:00, 19.84it/s, loss=5.35e-5]\n",
      "Epoch 2: val: 100%|██████████| 80/80 [00:03<00:00, 24.98it/s, loss=4.04e-5]\n",
      "Epoch 3: train: 100%|██████████| 717/717 [00:34<00:00, 20.73it/s, loss=3.02e-5]\n",
      "Epoch 3: val: 100%|██████████| 80/80 [00:03<00:00, 24.81it/s, loss=2.15e-5]\n",
      "Epoch 4: train: 100%|██████████| 717/717 [00:34<00:00, 20.65it/s, loss=1.63e-5]\n",
      "Epoch 4: val: 100%|██████████| 80/80 [00:03<00:00, 25.65it/s, loss=1.37e-5]\n",
      "Epoch 5: train: 100%|██████████| 717/717 [00:36<00:00, 19.87it/s, loss=1.02e-5]\n",
      "Epoch 5: val: 100%|██████████| 80/80 [00:03<00:00, 22.87it/s, loss=1.05e-5]\n",
      "Epoch 6: train:  14%|█▍        | 99/717 [00:05<00:31, 19.46it/s, loss=7.2e-6] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Inno\\PMLDL\\Assignments\\movie-recommender-system\\notebooks\\rating_loss-2.0.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m best_loss \u001b[39m=\u001b[39m \u001b[39m1e10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, NUM_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m val_one_epoch(model, val_dataloader, loss_fn, epoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m val_loss \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m best_loss:\n",
      "\u001b[1;32md:\\Inno\\PMLDL\\Assignments\\movie-recommender-system\\notebooks\\rating_loss-2.0.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loop \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(loader),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: train\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m loop:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     input_data, mask, target \u001b[39m=\u001b[39;49m batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     input_data, target, mask \u001b[39m=\u001b[39;49m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         input_data\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         target\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         mask\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     )\n",
      "File \u001b[1;32md:\\Code\\venvs\\movie-recommender-system-l_rFrim-\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Code\\venvs\\movie-recommender-system-l_rFrim-\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Code\\venvs\\movie-recommender-system-l_rFrim-\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Code\\venvs\\movie-recommender-system-l_rFrim-\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "\u001b[1;32md:\\Inno\\PMLDL\\Assignments\\movie-recommender-system\\notebooks\\rating_loss-2.0.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     mask_batch\u001b[39m.\u001b[39mappend(mask)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     target_batch\u001b[39m.\u001b[39mappend(target)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     torch\u001b[39m.\u001b[39mTensor(input_data_batch),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     torch\u001b[39m.\u001b[39mTensor(mask_batch)\u001b[39m.\u001b[39mbool(),\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mTensor(target_batch),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Inno/PMLDL/Assignments/movie-recommender-system/notebooks/rating_loss-2.0.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "best_loss = 1e10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    val_loss = val_one_epoch(model, val_dataloader, loss_fn, epoch)\n",
    "    if val_loss <= best_loss:\n",
    "        val_loss = best_loss\n",
    "        torch.save(model, \"../models/rating_loss_2\")\n",
    "\n",
    "\n",
    "best = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.510782Z",
     "iopub.status.busy": "2023-10-30T16:00:30.510404Z",
     "iopub.status.idle": "2023-10-30T16:00:30.592431Z",
     "shell.execute_reply": "2023-10-30T16:00:30.591458Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.510749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecSys(\n",
       "  (d1): Dropout(p=0.1, inplace=False)\n",
       "  (d2): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=1704, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc4): Linear(in_features=1024, out_features=1682, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../models/rating_loss_2\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_test(\n",
    "    model,\n",
    "    input_data: torch.Tensor,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        input_data = input_data.to(DEVICE)\n",
    "\n",
    "        model_out = model(input_data)\n",
    "\n",
    "    return model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(input_data, target, predicted):\n",
    "    input_ratings = input_data[USER_FEATURES:]\n",
    "    remove_indices = np.nonzero(input_ratings > 0)[0]\n",
    "    new_target = np.delete(target, remove_indices)\n",
    "    new_predicted = np.delete(predicted, remove_indices)\n",
    "\n",
    "    return new_target, new_predicted\n",
    "\n",
    "\n",
    "def sort_args(x, n):\n",
    "    return np.argsort(-x)[:n]\n",
    "\n",
    "\n",
    "def top_intersection(target, predicted, top_n=20):\n",
    "    return list(set(sort_args(target, top_n)).intersection(sort_args(predicted, top_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(retrieval_precisions)=2546\n",
      "np.mean(retrieval_precisions)=0.86771405\n",
      "np.max(retrieval_precisions)=1.0\n",
      "np.min(retrieval_precisions)=0.0\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics.functional.ranking import retrieval_precision\n",
    "\n",
    "k = 10\n",
    "retrieval_precisions = []\n",
    "\n",
    "for input_data, _, masked_target in val_dataset:\n",
    "    predictions = greedy_test(model, torch.Tensor([input_data]))\n",
    "    target = masked_target\n",
    "    predicted = predictions[0].cpu().numpy()\n",
    "\n",
    "    new_target, new_predicted = get_new_data(input_data, target, predicted)\n",
    "\n",
    "    nonzero_targets = new_target > 0\n",
    "    relevant_predicted = new_predicted\n",
    "\n",
    "    retrieval_precisions.append(\n",
    "        retrieval_precision(\n",
    "            torch.Tensor(relevant_predicted), torch.Tensor(nonzero_targets), k\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"{len(retrieval_precisions)=}\")\n",
    "print(f\"{np.mean(retrieval_precisions)=}\")\n",
    "print(f\"{np.max(retrieval_precisions)=}\")\n",
    "print(f\"{np.min(retrieval_precisions)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(intersections)=2546\n",
      "np.mean(intersections)=3.10840534171249\n",
      "np.max(intersections)=10\n",
      "np.min(intersections)=0\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "intersections = []\n",
    "for input_data, _, target in val_dataset:\n",
    "    predictions = greedy_test(model, torch.Tensor([input_data]))\n",
    "    predicted = predictions[0].cpu().numpy()\n",
    "\n",
    "    new_target, new_predicted = get_new_data(input_data, target, predicted)\n",
    "\n",
    "    nonzero_targets = new_target[new_target > 0]\n",
    "    relevant_predicted = new_predicted[new_predicted > 0.2]\n",
    "\n",
    "    intersections.append(len(top_intersection(nonzero_targets, relevant_predicted, k)))\n",
    "print(f\"{len(intersections)=}\")\n",
    "print(f\"{np.mean(intersections)=}\")\n",
    "print(f\"{np.max(intersections)=}\")\n",
    "print(f\"{np.min(intersections)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 215,  214,  260,   30,  264,  603,  309,  123,  209, 1203,  477,\n",
       "        478,  413,  258,  356,  606,  322,  968,  134,  233, 1049,  317,\n",
       "        434,  327,  257,  614,  315,  704, 1220,  314,  426,  312,  479,\n",
       "        422,  130,  877,  268, 1027,  688,  281,  299,  510,  182,   78,\n",
       "        513,  583,  527,  519,  677,  361,  173,   98,  749,  171,   94,\n",
       "        346,   70,  302,  538,  483,   96,   49,  486,  116,  271,  199,\n",
       "        944,  878,  891,  196,  303,  495,  660,  497,  661,  499,  192,\n",
       "        658,  321], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = target > 0\n",
    "np.argsort(t)[len(t) - sum(t) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "for input_data, _, target in val_dataset:\n",
    "    predictions = greedy_test(model, torch.Tensor([input_data]))\n",
    "    predicted = predictions[0].cpu().numpy()\n",
    "\n",
    "    new_target, new_predicted = get_new_data(input_data, target, predicted)\n",
    "\n",
    "    t = new_target > 0\n",
    "    all_targets.append(np.argsort(t)[len(t) - sum(t) :])\n",
    "    all_predictions.append(np.argsort(-new_predicted))\n",
    "\n",
    "    t = target > 0\n",
    "    # all_targets.append(np.argsort(t)[len(t)-sum(t):])\n",
    "    # all_predictions.append(np.argsort(-predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379484158156585"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(all_targets, all_predictions, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
